"""
Synesthesia AI - Main Agent
SpoonOS-based AI agent for audio-to-visual synesthesia mapping
Integrates audio processing, AI interpretation, and OSC visualization
"""

import json
import time
import os
from pathlib import Path
from typing import Dict, Optional

from audio_processor import AudioProcessor
from bridge_osc import OSCBridge, SynesthesiaMapper


class SynesthesiaAgent:
    """
    Main AI Agent for Synesthesia Media Art

    Workflow:
    1. Capture audio from microphone (AudioProcessor)
    2. Extract audio features (FFT, RMS, onset)
    3. Map features to visual parameters (SynesthesiaMapper)
    4. Send OSC commands to visual engine (OSCBridge)
    5. (Optional) Learn and update mapping rules with AI
    """

    def __init__(
        self,
        config_path: str = "config/mapping_rules.json",
        osc_host: str = "127.0.0.1",
        osc_port: int = 12000,
        sample_rate: int = 44100,
        buffer_size: int = 1024
    ):
        """
        Initialize Synesthesia Agent

        Args:
            config_path: Path to mapping rules JSON
            osc_host: OSC server host (visual engine)
            osc_port: OSC server port
            sample_rate: Audio sample rate
            buffer_size: Audio buffer size
        """
        print("=" * 60)
        print("SYNESTHESIA AI - Brain Engine")
        print("=" * 60)

        # Load mapping rules
        self.config_path = Path(config_path)
        self.mapping_rules = self.load_mapping_rules()

        # Initialize OSC bridge
        self.osc_bridge = OSCBridge(host=osc_host, port=osc_port)

        # Initialize synesthesia mapper
        self.mapper = SynesthesiaMapper(self.osc_bridge, self.mapping_rules)

        # Initialize audio processor with callback
        self.audio_processor = AudioProcessor(
            sample_rate=sample_rate,
            buffer_size=buffer_size,
            callback=self.on_audio_features
        )

        # Statistics
        self.stats = {
            'frames_processed': 0,
            'onsets_detected': 0,
            'start_time': None
        }

        print("\n[âœ“] Synesthesia Agent initialized")
        print(f"    Config: {config_path}")
        print(f"    OSC: {osc_host}:{osc_port}")
        print(f"    Audio: {sample_rate}Hz, buffer={buffer_size}")
        print()

    def load_mapping_rules(self) -> Dict:
        """
        Load synesthesia mapping rules from JSON config

        Returns:
            Dictionary with mapping rules
        """
        try:
            with open(self.config_path, 'r', encoding='utf-8') as f:
                rules = json.load(f)
            print(f"[âœ“] Loaded mapping rules: {self.config_path}")
            return rules
        except FileNotFoundError:
            print(f"[!] Config file not found: {self.config_path}")
            print("    Using default mapping rules")
            return self.get_default_rules()
        except json.JSONDecodeError as e:
            print(f"[!] Invalid JSON in config: {e}")
            print("    Using default mapping rules")
            return self.get_default_rules()

    def save_mapping_rules(self):
        """
        Save current mapping rules back to JSON
        (for AI learning updates)
        """
        try:
            # Ensure directory exists
            self.config_path.parent.mkdir(parents=True, exist_ok=True)

            # Write with pretty formatting
            with open(self.config_path, 'w', encoding='utf-8') as f:
                json.dump(self.mapping_rules, f, indent=2, ensure_ascii=False)

            print(f"[âœ“] Saved updated mapping rules to {self.config_path}")
        except Exception as e:
            print(f"[!] Failed to save mapping rules: {e}")
    
    def update_ai_reasoning(self):
        """
        SpoonOS ì—ì´ì „íŠ¸ê°€ ì£¼ê¸°ì ìœ¼ë¡œ í˜¸ì¶œí•˜ì—¬
        ìŒì•… ë¶„ìœ„ê¸°ì— ë”°ë¼ ë§¤í•‘ ê·œì¹™ì„ ìŠ¤ìŠ¤ë¡œ ìˆ˜ì •í•˜ëŠ” í•¨ìˆ˜
        """
        print("\n[ðŸ§ ] AI Agent is thinking... (Updating Rules)")
        
        # 1. í˜„ìž¬ ì˜¤ë””ì˜¤ í†µê³„ ìˆ˜ì§‘ (ìµœê·¼ 5ì´ˆê°„ì˜ ë°ì´í„°)
        if not self.recent_rms_values:
            return
            
        avg_rms = sum(self.recent_rms_values) / len(self.recent_rms_values)
        self.recent_rms_values.clear() # ì´ˆê¸°í™”

        # -------------------------------------------------------------
        # [SpoonOS ì˜ì—­] ì‹¤ì œë¡œëŠ” ì—¬ê¸°ì„œ LLMì—ê²Œ avg_rms ë“±ì˜ ë°ì´í„°ë¥¼ ì£¼ê³  íŒë‹¨ì„ ìš”ì²­í•¨
        # ì§€ê¸ˆì€ ê°„ë‹¨í•œ ë¡œì§ìœ¼ë¡œ ì‹œë®¬ë ˆì´ì…˜:
        # -------------------------------------------------------------
        
        # ì˜ˆì‹œ ë¡œì§: ì†Œë¦¬ê°€ ì•„ì£¼ í¬ë©´(ê²©ì •ì ) -> ìž…ìžë¥¼ í¬ê²Œ, ìƒ‰ìƒì„ ë¶‰ê²Œ ë³€ê²½
        if avg_rms > 0.3: 
            print("   â†³ Mood: Intense/Energetic! Increasing particles.")
            new_size_range = [20, 100] # ìž…ìž í¬ê¸° ëŒ€í­ ì¦ê°€
            new_hue_base = 0           # ë¶‰ì€ìƒ‰ ê³„ì—´ (Red)
        else:
            print("   â†³ Mood: Calm/Ambient. Decreasing particles.")
            new_size_range = [2, 10]   # ìž…ìž í¬ê¸° ì¶•ì†Œ
            new_hue_base = 200         # í‘¸ë¥¸ìƒ‰ ê³„ì—´ (Blue)

        # 2. mapping_rules ë‚´ë¶€ ê°’ ìˆ˜ì • (Self-Correction)
        # self.mapping_rulesëŠ” ë”•ì…”ë„ˆë¦¬ì´ë¯€ë¡œ ì§ì ‘ ìˆ˜ì • ê°€ëŠ¥
        
        # ìž…ìž í¬ê¸° ê·œì¹™ ìˆ˜ì •
        self.mapping_rules["rules"]["particle_mapping"]["size_range"] = new_size_range
        
        # ë² ì´ìŠ¤(ì €ìŒ) ìƒ‰ìƒ ê·œì¹™ ìˆ˜ì •
        self.mapping_rules["rules"]["color_mapping"]["frequency_ranges"]["bass"]["hue"] = [new_hue_base, new_hue_base + 30]

        # 3. ë§¤í¼(Mapper)ì—ê²Œ ë³€ê²½ëœ ê·œì¹™ ì¦‰ì‹œ ì ìš©
        # (ì¤‘ìš”: ì´ê±¸ í•´ì¤˜ì•¼ SynesthesiaMapperê°€ ë°”ë€ ê·œì¹™ìœ¼ë¡œ ê³„ì‚°í•¨)
        self.mapper.rules = self.mapping_rules
        
        # (ì„ íƒ) ë³€ê²½ëœ ê·œì¹™ ì €ìž¥
        # self.save_mapping_rules()
        
    def on_audio_features(self, features: Dict):
        """
        Callback when audio features are extracted
        This is called by AudioProcessor in real-time

        Args:
            features: Dictionary with audio features
        """
        # Update statistics
        self.stats['frames_processed'] += 1
        if features.get('onset', False):
            self.stats['onsets_detected'] += 1

        # Map audio features to visual parameters and send OSC
        self.mapper.process_audio_features(features)

        # Optional: Print status every N frames
        if self.stats['frames_processed'] % 50 == 0:
            self.print_status(features)

    def print_status(self, features: Dict):
        """
        Print current status (for monitoring)

        Args:
            features: Latest audio features
        """
        elapsed = time.time() - self.stats['start_time'] if self.stats['start_time'] else 0
        fps = self.stats['frames_processed'] / elapsed if elapsed > 0 else 0

        print(f"[{self.stats['frames_processed']:05d}] "
              f"RMS: {features.get('rms', 0):.3f} | "
              f"Freq: {features.get('dominant_freq', 0):.1f}Hz | "
              f"Onsets: {self.stats['onsets_detected']} | "
              f"FPS: {fps:.1f}")

    def start(self):
        """
        Start the synesthesia engine
        """
        print("[â†’] Starting Synesthesia Engine...")
        print("    Listening to microphone...")
        print("    Press Ctrl+C to stop\n")

        self.stats['start_time'] = time.time()

        # Start audio processing
        self.audio_processor.start()

        try:
            # Keep running
            while True:
                time.sleep(0.1)

        except KeyboardInterrupt:
            print("\n\n[!] Stopping...")
        finally:
            self.stop()

    def stop(self):
        """
        Stop the synesthesia engine
        """
        # Stop audio processor
        self.audio_processor.stop()

        # Print final statistics
        elapsed = time.time() - self.stats['start_time'] if self.stats['start_time'] else 0
        print("\n" + "=" * 60)
        print("SESSION STATISTICS")
        print("=" * 60)
        print(f"Duration:        {elapsed:.1f} seconds")
        print(f"Frames:          {self.stats['frames_processed']}")
        print(f"Onsets detected: {self.stats['onsets_detected']}")
        if elapsed > 0:
            print(f"Avg FPS:         {self.stats['frames_processed'] / elapsed:.1f}")
        print("=" * 60)

    @staticmethod
    def get_default_rules() -> Dict:
        """
        Get default mapping rules if config file is missing

        Returns:
            Default mapping rules dictionary
        """
        return {
            "version": "1.0",
            "last_updated": time.strftime("%Y-%m-%dT%H:%M:%S"),
            "rules": {
                "color_mapping": {
                    "frequency_ranges": {
                        "bass": {
                            "hz": [20, 250],
                            "hue": [0, 30],
                            "saturation": 0.8
                        },
                        "mid": {
                            "hz": [250, 2000],
                            "hue": [60, 180],
                            "saturation": 0.6
                        },
                        "treble": {
                            "hz": [2000, 20000],
                            "hue": [200, 280],
                            "saturation": 0.9
                        }
                    }
                },
                "motion_mapping": {
                    "onset_velocity": 0.75,
                    "decay_rate": 0.95
                },
                "particle_mapping": {
                    "energy_to_count": "exponential",
                    "size_range": [5, 50]
                }
            },
            "learning_params": {
                "adaptation_rate": 0.1,
                "user_feedback_weight": 0.3
            }
        }
        


def main():
    """
    Main entry point
    """
    # Parse command line arguments (optional)
    import argparse

    parser = argparse.ArgumentParser(description="Synesthesia AI - Brain Engine")
    parser.add_argument(
        '--config',
        default='config/mapping_rules.json',
        help='Path to mapping rules config (default: config/mapping_rules.json)'
    )
    parser.add_argument(
        '--osc-host',
        default='127.0.0.1',
        help='OSC host for visual engine (default: 127.0.0.1)'
    )
    parser.add_argument(
        '--osc-port',
        type=int,
        default=12000,
        help='OSC port for visual engine (default: 12000)'
    )
    parser.add_argument(
        '--sample-rate',
        type=int,
        default=44100,
        help='Audio sample rate (default: 44100)'
    )
    parser.add_argument(
        '--buffer-size',
        type=int,
        default=1024,
        help='Audio buffer size (default: 1024)'
    )

    args = parser.parse_args()

    # Create and start agent
    agent = SynesthesiaAgent(
        config_path=args.config,
        osc_host=args.osc_host,
        osc_port=args.osc_port,
        sample_rate=args.sample_rate,
        buffer_size=args.buffer_size
    )

    agent.start()
    
    


if __name__ == "__main__":
    main()
